---
title: "Task 3: Evaluate Techniques for Wifi Locationing"
output: html_notebook
---

This notebook contains the answers to Task 3: Evaluate Techniques for Wifi Locationing.

```{r - Initial imports}
library(RMySQL)

library(caret)

library(tidyverse)
library(readxl)
library(knitr)
library(ggplot2)
library(ggfortify)

library(forecast)

library(lubridate)
library(plyr)
library(plotly)


library(gbm)
library(Rcpp)
```


*Retrieve data*

The UJIIndoorLoc database (http://archive.ics.uci.edu/ml/datasets/UJIIndoorLoc) covers three buildings of Universitat Jaume I with 4 or more floors and almost 110.000m2. It can be used for classification, e.g. actual building and floor identification, or regression, e.g. actual longitude and latitude estimation.

The database consists of 19937 training/reference records (trainingData.csv file) and 1111 validation/test records (validationData.csv file).
The 529 attributes contain the WiFi fingerprint, the coordinates where it was taken, and other useful information.
Each WiFi fingerprint can be characterized by the detected Wireless Access Points (WAPs) and the corresponding Received Signal Strength Intensity (RSSI). The intensity values are represented as negative integer values ranging -104dBm (extremely poor signal) to 0dbM. The positive value 100 is used to denote when a WAP was not detected. During the database creation, 520 different WAPs were detected. Thus, the WiFi fingerprint is composed by 520 intensity values.

_Then the coordinates (latitude, longitude, floor) and Building ID are provided as the attributes to be predicted._
The particular space (offices, labs, etc.) and the relative position (inside/outside the space) where the capture was taken have been recorded. Outside means that the capture was taken in front of the door of the space.
Information about who (user), how (android device & version) and when (timestamp) WiFi capture was taken is also recorded.

The datasets contain the following columns:
Attribute 001 (WAP001): Intensity value for WAP001. Negative integer values from -104 to 0 and +100. Positive value 100 used if WAP001 was not detected.
....
Attribute 520 (WAP520): Intensity value for WAP520. Negative integer values from -104 to 0 and +100. Positive Vvalue 100 used if WAP520 was not detected.
Attribute 521 (Longitude): Longitude. Negative real values from -7695.9387549299299000 to -7299.786516730871000
Attribute 522 (Latitude): Latitude. Positive real values from 4864745.7450159714 to 4865017.3646842018.
Attribute 523 (Floor): Altitude in floors inside the building. Integer values from 0 to 4.
Attribute 524 (BuildingID): ID to identify the building. Measures were taken in three different buildings. Categorical integer values from 0 to 2.
Attribute 525 (SpaceID): Internal ID number to identify the Space (office, corridor, classroom) where the capture was taken. Categorical integer values.
Attribute 526 (RelativePosition): Relative position with respect to the Space (1 - Inside, 2 - Outside in Front of the door). Categorical integer values.
Attribute 527 (UserID): User identifier (see database website above). Categorical integer values.
Attribute 528 (PhoneID): Android device identifier (see database website above). Categorical integer values.
Attribute 529 (Timestamp): UNIX Time when the capture was taken. Integer value.


**Retrieve data from memory:**
```{r - Read the datasets from memory}
df_train<-read.csv('./UJIndoorLoc/trainingData.csv')
df_train

df_validation<-read.csv('./UJIndoorLoc/validationData.csv')
df_validation
```

```{r - Check column names}
length(names(df_train %>% select(starts_with("WAP"))))
names(df_train %>% select(!starts_with("WAP")))

length(names(df_validation %>% select(starts_with("WAP"))))
names(df_validation %>% select(!starts_with("WAP")))
```
The dataset contains the expected columns.

*Initial Preprocessing* 

```{r - Confirm datatypes of each column}
table(sapply(df_train, class))
table(sapply(df_validation, class))
```
All columns are originally integer, except for longitude and latitude which are numeric (floats). All columns seem to be correct except for the timestamp. I will convert timestamp into a more readable format: Datetime.
```{r - Convert timestamp into datetime}
df_train$DateTime <- as.POSIXct((df_train$TIMESTAMP), origin="1970-01-01") #Default origin time
df_validation$DateTime <- as.POSIXct((df_validation$TIMESTAMP), origin="1970-01-01") #Default origin time
```


```{r - Are there missing values?}
any(is.na(df_train))
any(is.na(df_validation))
```
No null values, no need to handle them.

*Initial Data exploration of the data:*


```{r - Plot WAP variables in a single graph.}
hist(stack(df_train %>% select(starts_with("WAP")))$values,xlab="WAP power",main="Distribution of WAP intensity")
```
As expected most entries are a null reading (represented as a '100').
Let's filter out these entries to get a better reading:

```{r -  Plot WAP variables in a single graph without null readings}
hist((stack(df_train %>% select(starts_with("WAP"))) %>% filter(values <100))$values,xlab="WAP power",main="Distribution of WAP intensity")
```
As expected we now have a good looking normal distribution. It is slightly skewed to the right.


```{r - Plot of the not related to Wireless Access Points power}
hist(df_train$LONGITUDE,xlab="Longitude",main="Distribution of Longitudes")
hist(df_train$LATITUDE,xlab="Latitude",main="Distribution of Latitude")
hist(df_train$FLOOR,xlab="Floor",main="Distribution of Floors")
hist(df_train$BUILDINGID,xlab="BuildingID",main="Distribution of BuildingIDs")
hist(df_train$SPACEID,xlab="SpaceIDs",main="Distribution of SpaceIDs")
hist(df_train$RELATIVEPOSITION,xlab="Relative Position",main="Distribution of Relative Positions")

hist(df_train$USERID,xlab="User ID",main="Distribution of UserIDs")
hist(df_train$PHONEID,xlab="Phone ID",main="Distribution of Phone IDs")
```


Let's confirm that the distributions are similar to the validation dataset:

```{r -  Plot WAP variables in a single graph without null readings}
hist((stack(df_validation %>% select(starts_with("WAP"))) %>% filter(values <100))$values,xlab="WAP power",main="Distribution of WAP intensity")
```

```{r - Plot of the not related to Wireless Access Points power}
hist(df_validation$LONGITUDE,xlab="Longitude",main="Distribution of Longitudes")
hist(df_validation$LATITUDE,xlab="Latitude",main="Distribution of Latitude")
hist(df_validation$FLOOR,xlab="Floor",main="Distribution of Floors")
hist(df_validation$BUILDINGID,xlab="BuildingID",main="Distribution of BuildingIDs")
hist(df_validation$SPACEID,xlab="SpaceIDs",main="Distribution of SpaceIDs")
hist(df_validation$RELATIVEPOSITION,xlab="Relative Position",main="Distribution of Relative Positions")

hist(df_validation$USERID,xlab="User ID",main="Distribution of UserIDs")
hist(df_validation$PHONEID,xlab="Phone ID",main="Distribution of Phone IDs")
```

The distributions are quite similar, the exceptions are in the SPACEID, RELATIVEPOSITION and USERID where the validation dataset has no variation. We will confirm this below:

```{r - Non-variant columns in validation df}
table(df_validation$SPACEID)
table(df_validation$RELATIVEPOSITION)
table(df_validation$USERID)
```
Ye, as expected all are null.

*2nd round of Preprocessing the data:*
**Sampling**
As mentioned in the Plan of attack, the dataset is too large. Therefore, I will utilize a random subset of the data for the machine learning portion of this project.
```{r - Gather random sample of 2500 entries from train dataset:}
set.seed(42) #Set seed to ensure reproducibility
df_train[sample(nrow(df_train), 2500),]
```

*ML Modeling*

Felice recomended to forecast in cascade, firstly classify the easiest parameters (such as building; floor; inside or out...) and then make a regression for location (longitude and latitude).

Let's do that.

The easiest parameter seems to be the relative position (in or out), then the Building ID and finally the floor.
Having these 3 parameters it will hopefully be easy to infer SpaceID through a last classification model.



**Relative Position**

First of all let's define the usable features and the target for this model:
```{r}
df_train_RP <- df_train %>% select(starts_with("WAP"),"RELATIVEPOSITION")
#Perform factorization on target column:
df_train_RP$RELATIVEPOSITION <- as.factor(df_train_RP$RELATIVEPOSITION) #Reconvert brand into binary column not integer.
```


I chose the following models because these are the ones I am most familiarized and from what I understood, provide good results right out of the bat.
```{r - 10 fold cross validation for 3 models to experiment}
svmfitControl <- trainControl(method = "repeatedcv", 
                              number = 10, # number of folds
                              repeats = 1) #the number of complete sets of folds to compute
gbmfitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 1)
rffitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 1)


```

Because this dataset is slightly unbalanced, I will attempt to train according to the kappa metric instead of accuracy.
(Practically, Cohen’s kappa removes the possibility of the classifier and a random guess agreeing and measures the number of predictions it makes that cannot be explained by a random guess. Furthermore, Cohen’s kappa tries to correct the evaluation bias by taking into account the correct classification by a random guess.)




```{r - Train Gradient Boost Classification model}
# tuneLenght = 1 (trains with 1 mtry value for RandomForest)
svmfitControl <- train(RELATIVEPOSITION~., #y/target
                 data = df_train_RP, #X/features
                 
                 method = "svmLinear", #ML algorithm
                 trControl=svmfitControl, #Apply CV to the training
                 tuneLength = 10, # Number of levels for each tuning parameters that should be generated
                 verbose = FALSE)

gbmFit1
```

As asked, in this part we are supposed to train a model using Stochastic Gradient Boosting, GBM, on the training set with 10-fold cross-validation and an Automatic Tuning Grid, which is what is coded above.

Train function chooses the model with the largest performance value (or smallest, for mean squared error in regression models), therefore there is no need to select the best iteration of the models.

```{r -  Ascertain how the model prioritized each feature in the GBM training}
varImp(gbmFit1)
```




















